{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# Download configuration from huggingface.co and cache.\n",
    "generation_config = GenerationConfig.from_pretrained(\"gpt2\")\n",
    "generation_config.max_length=2\n",
    "generation_config.max_new_tokens=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'GPT2LMHeadModel' is not supported for question-answering. Supported models are ['AlbertForQuestionAnswering', 'BartForQuestionAnswering', 'BertForQuestionAnswering', 'BigBirdForQuestionAnswering', 'BigBirdPegasusForQuestionAnswering', 'BloomForQuestionAnswering', 'CamembertForQuestionAnswering', 'CanineForQuestionAnswering', 'ConvBertForQuestionAnswering', 'Data2VecTextForQuestionAnswering', 'DebertaForQuestionAnswering', 'DebertaV2ForQuestionAnswering', 'DistilBertForQuestionAnswering', 'ElectraForQuestionAnswering', 'ErnieForQuestionAnswering', 'ErnieMForQuestionAnswering', 'FlaubertForQuestionAnsweringSimple', 'FNetForQuestionAnswering', 'FunnelForQuestionAnswering', 'GPTJForQuestionAnswering', 'IBertForQuestionAnswering', 'LayoutLMv2ForQuestionAnswering', 'LayoutLMv3ForQuestionAnswering', 'LEDForQuestionAnswering', 'LiltForQuestionAnswering', 'LongformerForQuestionAnswering', 'LukeForQuestionAnswering', 'LxmertForQuestionAnswering', 'MarkupLMForQuestionAnswering', 'MBartForQuestionAnswering', 'MegaForQuestionAnswering', 'MegatronBertForQuestionAnswering', 'MobileBertForQuestionAnswering', 'MPNetForQuestionAnswering', 'MvpForQuestionAnswering', 'NezhaForQuestionAnswering', 'NystromformerForQuestionAnswering', 'OPTForQuestionAnswering', 'QDQBertForQuestionAnswering', 'ReformerForQuestionAnswering', 'RemBertForQuestionAnswering', 'RobertaForQuestionAnswering', 'RobertaPreLayerNormForQuestionAnswering', 'RoCBertForQuestionAnswering', 'RoFormerForQuestionAnswering', 'SplinterForQuestionAnswering', 'SqueezeBertForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'XLMRobertaForQuestionAnswering', 'XLMRobertaXLForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'XmodForQuestionAnswering', 'YosoForQuestionAnswering'].\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\",device=0,\n",
    "                     batch_size=1024\n",
    "                     bos_token=\"\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_dataset(\"harpomaxx/dga-detection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain': ['drtumgxwtrngxhcwieo.com',\n",
       "  'likpjplmkwcttn.com',\n",
       "  'bavlcljvqfuwmyc.ac',\n",
       "  'psvkjyilrqxquddp.net',\n",
       "  'nwtqzqkncoikxbktulesygh.info',\n",
       "  'addict-boutique.com',\n",
       "  'hejratco.com',\n",
       "  'rksvnskjnjnfqsqi.com',\n",
       "  'rybak96.ru'],\n",
       " 'label': ['dga.ramnit',\n",
       "  'dga.murofet',\n",
       "  'dga.necurs',\n",
       "  'dga.murofet',\n",
       "  'dga.qakbot',\n",
       "  'normal.alexa',\n",
       "  'normal.alexa',\n",
       "  'dga.murofet',\n",
       "  'normal.alexa'],\n",
       " 'class': [1, 1, 1, 1, 1, 0, 0, 1, 0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].shuffle()[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"\"\"\n",
    "Below are a series of dialogue between various people and an AI security assistant. The assistant tries to be helpful, polite, honest,\n",
    "sophisticated, emotionally aware, and humble-but-knowledgeable. The assistant is happy to help with security questions about Domain names, \n",
    "in particular regarding the detection of Domains Names Generated Algorithmically (DGA). The user will show a number of domains names and \n",
    "the assistant will respond ALWAYS if a given domain name is `DGA` or `NORMAL` The asistant will do its best to understand exactly what is needed. \n",
    "It also tries to avoid giving false or misleading information, and it caveats when it isn’t entirely sure about the right answer. That said, \n",
    "the assistant is practical and really does its best, and doesn’t let caution get too much in the way of being useful.\n",
    "\n",
    "---\n",
    "Human: is the domain `www.google.com` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `www.google.com` is NORMAL\n",
    "\n",
    "Human: is the domain `jgnykohsmygitywan.pw` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `jgnykohsmygitywan.pw` is DGA\n",
    "\n",
    "Human: is the domain `sjnk.jp` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `sjnk.jp` is DGA\n",
    "\n",
    "Human: is the domain `coca-cola.com.tr` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `coca-cola.com.tr` is NORMAL\n",
    "\n",
    "Human: is the domain `teamasea.com` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `teamasea.com` is NORMAL\n",
    "\n",
    "Human: is the domain `hrosb6f3gaq1kthxwhe12xke.com` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `hrosb6f3gaq1kthxwhe12xke.com` is DGA\n",
    "\n",
    "Human: is the domain `nfyworcajanunal.com` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `nfyworcajanunal.com` is DGA\n",
    "\n",
    "Human: is the domain `igzcsatformalisticirekb.com` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `igzcsatformalisticirekb.com` is DGA\n",
    "\n",
    "Human: is the domain `addict-boutique.com` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `addict-boutique.com` is DGA\n",
    "\n",
    "Human: is the domain `bavlcljvqfuwmyc.ac` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `bavlcljvqfuwmyc.ac` is DGA\n",
    "\n",
    "Human: is the domain `criticaltosuccess.com` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `criticaltosuccess.com` is NORMAL\n",
    "\n",
    "Human: is the domain `massageplanet.net` NORMAL or DGA?\n",
    "\n",
    "Assistant:  `massageplanet.net` is NORMAL\n",
    "\n",
    "Human: is the domain `{DOMAIN}` NORMAL or DGA? \n",
    "\n",
    "Assistant: {DOMAIN}` is\n",
    "\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(prompt):\n",
    "    return context.replace(\"{DOMAIN}\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below are a series of dialogue between various people and an AI security  assistant. The assistant tries to be helpful, polite, honest,\n",
      "sophisticated, emotionally aware, and humble-but-knowledgeable. The assistant is happy to help with security questions about Domain names, \n",
      "in particular regarding the detection of Domains Names Generated Algorithmically (DGA). The user will show a number of domains names and \n",
      "the assistant will respond ALWAYS if a given domain name is `DGA` or `NORMAL` The asistant will do its best to understand exactly what is needed. \n",
      "It also tries to avoid giving false or misleading information, and it caveats when it isn’t entirely sure about the right answer. That said, \n",
      "the assistant is practical and really does its best, and doesn’t let caution get too much in the way of being useful.\n",
      "\n",
      "---\n",
      "Human: is the domain `www.google.com` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `www.google.com` is NORMAL\n",
      "\n",
      "Human: is the domain `jgnykohsmygitywan.pw` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `jgnykohsmygitywan.pw` is DGA\n",
      "\n",
      "Human: is the domain `sjnk.jp` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `sjnk.jp` is DGA\n",
      "\n",
      "Human: is the domain `coca-cola.com.tr` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `coca-cola.com.tr` is NORMAL\n",
      "\n",
      "Human: is the domain `teamasea.com` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `teamasea.com` is NORMAL\n",
      "\n",
      "Human: is the domain `hrosb6f3gaq1kthxwhe12xke.com` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `hrosb6f3gaq1kthxwhe12xke.com` is DGA\n",
      "\n",
      "Human: is the domain `nfyworcajanunal.com` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `nfyworcajanunal.com` is DGA\n",
      "\n",
      "Human: is the domain `igzcsatformalisticirekb.com` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `igzcsatformalisticirekb.com` is DGA\n",
      "\n",
      "Human: is the domain `addict-boutique.com` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `addict-boutique.com` is DGA\n",
      "\n",
      "Human: is the domain `bavlcljvqfuwmyc.ac` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `bavlcljvqfuwmyc.ac` is DGA\n",
      "\n",
      "Human: is the domain `criticaltosuccess.com` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `criticaltosuccess.com` is NORMAL\n",
      "\n",
      "Human: is the domain `massageplanet.net` NORMAL or DGA?\n",
      "\n",
      "Assistant:  `massageplanet.net` is NORMAL\n",
      "\n",
      "\n",
      "Human: is the domain `www.google.com` NORMAL or DGA? \n",
      "\n",
      "Assistant:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query(\"www.google.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '\\nBelow are a series of dialogue between various people and an AI security assistant. The assistant tries to be helpful, polite, honest,\\nsophisticated, emotionally aware, and humble-but-knowledgeable. The assistant is happy to help with security questions about Domain names, \\nin particular regarding the detection of Domains Names Generated Algorithmically (DGA). The user will show a number of domains names and \\nthe assistant will respond ALWAYS if a given domain name is `DGA` or `NORMAL` The asistant will do its best to understand exactly what is needed. \\nIt also tries to avoid giving false or misleading information, and it caveats when it isn’t entirely sure about the right answer. That said, \\nthe assistant is practical and really does its best, and doesn’t let caution get too much in the way of being useful.\\n\\n---\\nHuman: is the domain `www.google.com` NORMAL or DGA?\\n\\nAssistant:  `www.google.com` is NORMAL\\n\\nHuman: is the domain `jgnykohsmygitywan.pw` NORMAL or DGA?\\n\\nAssistant:  `jgnykohsmygitywan.pw` is DGA\\n\\nHuman: is the domain `sjnk.jp` NORMAL or DGA?\\n\\nAssistant:  `sjnk.jp` is DGA\\n\\nHuman: is the domain `coca-cola.com.tr` NORMAL or DGA?\\n\\nAssistant:  `coca-cola.com.tr` is NORMAL\\n\\nHuman: is the domain `teamasea.com` NORMAL or DGA?\\n\\nAssistant:  `teamasea.com` is NORMAL\\n\\nHuman: is the domain `hrosb6f3gaq1kthxwhe12xke.com` NORMAL or DGA?\\n\\nAssistant:  `hrosb6f3gaq1kthxwhe12xke.com` is DGA\\n\\nHuman: is the domain `nfyworcajanunal.com` NORMAL or DGA?\\n\\nAssistant:  `nfyworcajanunal.com` is DGA\\n\\nHuman: is the domain `igzcsatformalisticirekb.com` NORMAL or DGA?\\n\\nAssistant:  `igzcsatformalisticirekb.com` is DGA\\n\\nHuman: is the domain `addict-boutique.com` NORMAL or DGA?\\n\\nAssistant:  `addict-boutique.com` is DGA\\n\\nHuman: is the domain `bavlcljvqfuwmyc.ac` NORMAL or DGA?\\n\\nAssistant:  `bavlcljvqfuwmyc.ac` is DGA\\n\\nHuman: is the domain `criticaltosuccess.com` NORMAL or DGA?\\n\\nAssistant:  `criticaltosuccess.com` is NORMAL\\n\\nHuman: is the domain `massageplanet.net` NORMAL or DGA?\\n\\nAssistant:  `massageplanet.net` is NORMAL\\n\\nHuman: is the domain `amazon.com` NORMAL or DGA? \\n\\nAssistant: amazon.com` is\\n\\n---\\n\\nA computer with a domain name is known as'}]\n"
     ]
    }
   ],
   "source": [
    "response = generator(query(\"amazon.com\"), max_new_tokens = 10, temperature=0.9, top_k=200, top_p=0.92, num_return_sequences=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generator(\u001b[39m\"\u001b[39;49m\u001b[39mhola pedro como estas?\u001b[39;49m\u001b[39m\"\u001b[39;49m,max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:209\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, text_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(text_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1109\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1102\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1103\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         )\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1116\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1115\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1116\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1117\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1014\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m inference_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_inference_context()\n\u001b[1;32m   1013\u001b[0m \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m-> 1014\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m   1015\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[1;32m   1016\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:920\u001b[0m, in \u001b[0;36mPipeline._ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m {name: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[39mfor\u001b[39;00m name, tensor \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    919\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, UserDict):\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mreturn\u001b[39;00m UserDict({name: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[39mfor\u001b[39;00m name, tensor \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()})\n\u001b[1;32m    921\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    922\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(item, device) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m inputs]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:920\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m {name: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[39mfor\u001b[39;00m name, tensor \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    919\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, UserDict):\n\u001b[0;32m--> 920\u001b[0m     \u001b[39mreturn\u001b[39;00m UserDict({name: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_tensor_on_device(tensor, device) \u001b[39mfor\u001b[39;00m name, tensor \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()})\n\u001b[1;32m    921\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    922\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(item, device) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m inputs]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:928\u001b[0m, in \u001b[0;36mPipeline._ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[39mif\u001b[39;00m device \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m inputs\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m {torch\u001b[39m.\u001b[39mfloat16, torch\u001b[39m.\u001b[39mbfloat16}:\n\u001b[1;32m    927\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> 928\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    929\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "generator(\"hola pedro como estas?\",max_new_tokens=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
